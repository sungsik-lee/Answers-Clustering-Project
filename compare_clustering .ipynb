{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 유무 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 74)\n",
      "(39, 79)\n",
      "2번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "before_rand_index : 0.795\n",
      "after_rand_index : 0.795\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.719\n",
      "after Adjusted Mutual Information: 0.719\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
      " 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "before_rand_index : 0.603\n",
      "after_rand_index : 0.795\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.433\n",
      "after Adjusted Mutual Information: 0.719\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "before_rand_index : 0.397\n",
      "after_rand_index : 0.465\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.424\n",
      "after Adjusted Mutual Information: 0.466\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "before_rand_index : 0.894\n",
      "after_rand_index : 0.894\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.826\n",
      "after Adjusted Mutual Information: 0.826\n",
      "\n",
      "\n",
      "(46, 49)\n",
      "(46, 54)\n",
      "4번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 1 0 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "before_rand_index : 0.002\n",
      "after_rand_index : 0.830\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.097\n",
      "after Adjusted Mutual Information: 0.776\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : -0.039\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.069\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 0.304\n",
      "after_rand_index : 0.913\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.397\n",
      "after Adjusted Mutual Information: 0.863\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 1 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 0.255\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.173\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "(52, 37)\n",
      "(52, 54)\n",
      "6번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1]\n",
      "before_rand_index : 0.366\n",
      "after_rand_index : 0.710\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.299\n",
      "after Adjusted Mutual Information: 0.611\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1]\n",
      "before_rand_index : 0.416\n",
      "after_rand_index : 0.710\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.391\n",
      "after Adjusted Mutual Information: 0.600\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "before_rand_index : 0.416\n",
      "after_rand_index : 0.584\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.335\n",
      "after Adjusted Mutual Information: 0.473\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1]\n",
      "before_rand_index : 0.646\n",
      "after_rand_index : 0.470\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.537\n",
      "after Adjusted Mutual Information: 0.481\n",
      "\n",
      "\n",
      "(30, 91)\n",
      "(30, 100)\n",
      "3번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 0.743\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.698\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "before_rand_index : 0.051\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.181\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "before_rand_index : 0.522\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.535\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 0.138\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.266\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "(30, 69)\n",
      "(30, 78)\n",
      "5번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 2 0 1 2 2 1 2 1 2 1 1 0]\n",
      "[2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 0.484\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.523\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 2 0 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2]\n",
      "before_rand_index : 0.898\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.892\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import * \n",
    "from tf_idf import *\n",
    "from clustering import *\n",
    "\n",
    "\n",
    "\n",
    "stop_word = [  '1)', '2)', '3)',  '이고', '이므로' , '이면' , \"이다\" , '에는',  '에서', \"으로\", \"으므로\", ',', '이', '가', '에' , '한다', '다', '이므로', '이므로','하므로' ]\n",
    "stop_tag = ['JKS' ,'JKC' ,'JKG' ,'JKO' ,'JKB' ,'JKV' ,'JKQ' ,'JX' ,'JC', 'EP' ,'EF' ,'EC' ,'ETN' ,'ETM', 'XSN', 'XSV', 'XSA', 'XSM']\n",
    "true_label={1 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            2 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1],\n",
    "            3 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1], \n",
    "            4 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            5 : [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2],\n",
    "            6 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            7 : [0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}\n",
    "\n",
    "\n",
    "\n",
    " # 원하는 클러스터 수를 설정하세요\n",
    "methods = ['cos_dis_kmeans', 'basic_spectral', 'tuned_spectral', 'LDA']\n",
    "\n",
    "prob = [2, 4, 6, 3, 5]\n",
    "for prob_num in prob:\n",
    "    num=len(true_label[prob_num])\n",
    "    if prob_num ==5:\n",
    "        n_clusters = 3\n",
    "    else:\n",
    "        n_clusters = 2\n",
    "    kiwi, kiwi2, answer = generate_tokenizer(prob_num, num, concept_list)\n",
    "    before_tf_idf= math_tfidf(prob_num, norm = False,  concept=False, nrange=(1,1), num_df=round(num/10), text_df=round(num/20),  answers=answer, stop_tag=stop_tag, stop_word=stop_word, concept_list = concept_list, kiwi=kiwi2, decay = 2) #70 #90\n",
    "    math_tf_idf = math_tfidf(prob_num, norm =False, concept=False,  nrange=(1,1), num_df=round(num/10), text_df=round(num/20), answers=answer, stop_tag=stop_tag, stop_word=stop_word, concept_list = concept_list, kiwi=kiwi, decay = 2) #70 #90\n",
    "\n",
    "    print(f'{prob_num}번째 문제')\n",
    "    for method in methods:\n",
    "        a= clustering(before_tf_idf, math_tf_idf, n_clusters, method , true_label[prob_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-range 유무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 79)\n",
      "(39, 164)\n",
      "2번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "before_rand_index : 0.795\n",
      "after_rand_index : 0.894\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.719\n",
      "after Adjusted Mutual Information: 0.826\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "before_rand_index : 0.795\n",
      "after_rand_index : 0.894\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.719\n",
      "after Adjusted Mutual Information: 0.826\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "before_rand_index : 0.465\n",
      "after_rand_index : 0.894\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.466\n",
      "after Adjusted Mutual Information: 0.826\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "before_rand_index : 0.894\n",
      "after_rand_index : 0.894\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.826\n",
      "after Adjusted Mutual Information: 0.826\n",
      "\n",
      "\n",
      "(46, 54)\n",
      "(46, 61)\n",
      "4번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "before_rand_index : 0.830\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.776\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1]\n",
      "before_rand_index : 0.913\n",
      "after_rand_index : 0.913\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.863\n",
      "after Adjusted Mutual Information: 0.865\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "(52, 54)\n",
      "(52, 116)\n",
      "6번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1]\n",
      "[1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1]\n",
      "before_rand_index : 0.710\n",
      "after_rand_index : 0.525\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.611\n",
      "after Adjusted Mutual Information: 0.436\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1]\n",
      "before_rand_index : 0.710\n",
      "after_rand_index : 0.710\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.600\n",
      "after Adjusted Mutual Information: 0.600\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "before_rand_index : 0.584\n",
      "after_rand_index : 0.710\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.473\n",
      "after Adjusted Mutual Information: 0.600\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "before_rand_index : 0.470\n",
      "after_rand_index : 0.646\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 0.481\n",
      "after Adjusted Mutual Information: 0.615\n",
      "\n",
      "\n",
      "(30, 100)\n",
      "(30, 194)\n",
      "3번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "(30, 78)\n",
      "(30, 144)\n",
      "5번째 문제\n",
      "cos_dis_kmeans\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "basic_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "tuned_spectral\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n",
      "LDA\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "before_rand_index : 1.000\n",
      "after_rand_index : 1.000\n",
      "\n",
      "\n",
      "before Adjusted Mutual Information: 1.000\n",
      "after Adjusted Mutual Information: 1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import * \n",
    "from tf_idf import *\n",
    "from clustering import *\n",
    "\n",
    "stop_word = [  '1)', '2)', '3)',  '이고', '이므로' , '이면' , \"이다\" , '에는',  '에서', \"으로\", \"으므로\", ',', '이', '가', '에' , '한다', '다', '이므로', '이므로','하므로' ]\n",
    "stop_tag = ['JKS' ,'JKC' ,'JKG' ,'JKO' ,'JKB' ,'JKV' ,'JKQ' ,'JX' ,'JC', 'EP' ,'EF' ,'EC' ,'ETN' ,'ETM', 'XSN', 'XSV', 'XSA', 'XSM']\n",
    "true_label={1 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            2 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1],\n",
    "            3 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1], \n",
    "            4 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            5 : [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2],\n",
    "            6 : [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            7 : [0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}\n",
    "\n",
    "\n",
    "\n",
    " # 원하는 클러스터 수를 설정하세요\n",
    "methods = ['cos_dis_kmeans', 'basic_spectral', 'tuned_spectral', 'LDA']\n",
    "\n",
    "prob = [2, 4, 6, 3, 5]\n",
    "\n",
    "for prob_num in prob:\n",
    "    num=len(true_label[prob_num])\n",
    "    if prob_num ==5:\n",
    "        n_clusters = 3\n",
    "    else:\n",
    "        n_clusters = 2\n",
    "    kiwi, kiwi2, answer = generate_tokenizer(prob_num, num, concept_list)\n",
    "    before_tf_idf= math_tfidf(prob_num, norm = False,  concept = False, nrange=(1,1), num_df=round(num/10), text_df=round(num/20),  answers=answer, stop_tag=stop_tag, stop_word=stop_word, concept_list = concept_list, kiwi=kiwi, decay = 2) #70 #90\n",
    "    math_tf_idf = math_tfidf(prob_num, norm =False, concept = False,  nrange=(2,2), num_df=round(num/10), text_df=round(num/20), answers=answer, stop_tag=stop_tag, stop_word=stop_word, concept_list = concept_list, kiwi=kiwi, decay = 2) #70 #90\n",
    "\n",
    "    print(f'{prob_num}번째 문제')\n",
    "    for method in methods:\n",
    "        a= clustering(before_tf_idf, math_tf_idf, n_clusters, method , true_label[prob_num])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
